# SecureLocalAI KR (仮) — 보안 특화 로컬 AI 지식 허브

> 작성일: 2026-02-19  
> 등급: **B** (A급 잠재력, 실질 런칭 허들 해결 시 승격)  
> 상태: 기술 타당성 검토 중

---

## 1. 핵심 컨셉

기업 보안 및 전문직 프라이버시를 위해, 외부 유출 없이 **내 PC(로컬)**에서만 작동하는 AI 지식 관리 도구.

- **오프라인 완전 동작** — 인터넷 없이도 내 파일을 분석하고 정리
- **초경량 모델** — 3.8B~4B급 모델을 4-bit 양자화하여 **약 2~2.5GB**
- **보안팀 친화적** — Tauri + Rust 기반 네이티브 빌드로 바이러스 오진 최소화

---

## 2. 기술적 논의 정리

### 2-1. 모델 사이즈 선택: 9B vs 4B vs 3.8B

| 모델 | 4-bit 크기 | RAM 점유 | 장점 | 단점 |
|------|-----------|---------|------|------|
| Qwen 3.5 9B | ~5GB | ~7GB | 범용 추론 강력 | **앱 파일 5GB = 유저 저항감 큼** |
| Qwen 3.5 4B | ~2.5GB | ~4GB | 범용 + 한국어 강점, 72B급 성능에 근접 | 복잡한 다단계 추론에서 역체감 |
| Phi-4 mini 3.8B | ~2.2GB | ~3.5GB | 툴콜링/추론 특화, 128K 컨텍스트 | 한국어 성능 미지수 |

**현재 결론:**
- 9B(5GB)는 "앱 파일이 5GB"라는 심리적 장벽이 너무 높음
- **4B급(2~2.5GB)이 최적점** — "깔아볼 만한 크기"이면서 실용적 성능 확보
- Phi-4 mini는 툴콜링 특화, Qwen 3.5 4B는 범용+한국어 → 용도에 따라 선택

### 2-2. 툴콜링 벤치마크 (2026.02 기준)

```
Agent Score (판단력 — "언제 툴을 써야 하는가") 벤치마크:
  phi4-mini:3.8b     → 0.880 (최상위)
  qwen3:4b           → 0.880 (최상위, 동률)
  qwen3:0.6b         → 0.880 (놀랍게도 동률)
  qwen3:1.7b         → 하위 (비단조적 성능 분포)

핵심 인사이트:
  - 3B~4B급에서도 "툴을 불러야 할지 말아야 할지" 판단은 최상위급
  - 문제는 "불러서 뭘 시킬지"의 품질 → 이건 태스크 설계로 커버 가능
  - BitNet 2B-4T도 "완벽한 JSON 툴콜" 가능 (CPU 위에서!)
```

### 2-3. 보안 프로그램(EDR/AV) 충돌 문제

**백그라운드에서 돌릴 때 잡아먹히는 이유:**
1. CPU/RAM 급격한 점유 → 마이닝 악성코드로 오해
2. 파일 지속 접근(인덱싱) → 정보 탈취 행위로 오해
3. 서명 없는 바이너리 → 100% 차단

**해결 전략:**
1. ✅ **트레이 앱(Tray App)** 방식 사용 (윈도우 서비스 X)
   - 유저가 인지하는 "앱"은 보안 프로그램이 관대하게 봄
2. ✅ **EV 코드 사이닝** 필수
   - 디지털 서명으로 초기 평판 점수 확보 → 오진율 획기적 감소
3. ✅ **Low-Priority 프로세스** 스케줄링
   - CPU 10~20%로 제한, 유저 활동 감지 시 인퍼런스 일시 정지
   - "시스템을 망가뜨리는 애가 아님"을 보안 프로그램에 증명
4. ✅ **국내 AV 벤더(안랩, 알약) 평판 등록**
   - 화이트리스트/오진 신고 프로세스를 사전에 진행

---

## 3. 시장 환경 (2026 한국)

### 3-1. 로컬 AI가 먹히는 구조적 이유

```
2026년 한국 보안 시장 팩트:
├── 정보보호 투자 2조 4230억 원 (4년간 60.8% 증가)
├── AI 기본법 2026.01 시행 → 고위험군(금융/채용) 데이터 주권 입증 의무
├── 기업 83%가 AI 보안 사고 경험 → Shadow AI(직원 몰래 ChatGPT 사용)가 최대 골칫거리
├── 금융 AI 시장 3조 2천억 원 규모 (연평균 38.2% 성장)
└── "모든 회사가 작은 AI 데이터센터가 되는 시대" 전망
```

### 3-2. 로컬 AI의 틈새 (클라우드 AI가 못 하는 것)

1. **DRM 문서 분석:** 암호화 문서를 복호화→클라우드 전송→재암호화 하는 대신, 로컬 메모리에서만 처리
2. **에어갭 환경:** 인터넷 물리적 차단된 연구소/생산현장에서 유일한 AI 도구
3. **Shadow AI 공식화:** AI를 막기만 하면 생산성↓, 검증된 로컬 모델을 공식 배포하는 방식

### 3-3. 리스크

```
🔴 대기업이 클라우드 AI(Copilot, Azure OpenAI)를 열어줄 경우 가치 감소
   → 대응: "내 로컬 파일을 직접 핸들링하는 능력"은 클라우드가 못 함
🔴 앱 파일 크기 (모델 2~5GB) → 배포/설치 허들
   → 대응: Ollama 등 로컬 추론 엔진과 연동하는 "공유 모델" 방식
🔴 보안 프로그램 오진 가능성
   → 대응: 위 2-3 해결 전략 참조
```

---

## 4. 유스케이스 후보

| # | 태스크 | 모델 적합성 | 난이도 | 차별화 |
|---|--------|-----------|--------|--------|
| 1 | **파일 위계 자동 설계** — 어질러진 파일을 분석해 폴더 구조 제안 & 이동 | ⭐⭐⭐⭐⭐ | 중 | 높음 |
| 2 | **로컬 기밀 문서 요약** — 외부 유출 없이 사내 문서 요약본 추출 | ⭐⭐⭐⭐ | 중 | 높음 |
| 3 | **시맨틱 파일 검색** — "지난달 김과장이 보낸 계약서" 같은 자연어 검색 | ⭐⭐⭐⭐ | 상 | 매우 높음 |
| 4 | **백그라운드 인덱싱** — 새 파일이 생길 때 자동으로 메타데이터 태깅 | ⭐⭐⭐ | 상 | 중 |

---

## 5. PoC(타당성 테스트) 플랜

### Phase 1: 성능 체킹
- Ollama/llama.cpp로 Qwen 3.5 4B (4-bit GGUF) 로드
- DDR5 16GB 환경에서 TPS(초당 토큰) 측정 → 15~20 TPS 이상이면 합격
- CPU/RAM 점유율 모니터링

### Phase 2: 태스크 품질 확인
- 실제 내 파일 10개를 주고 분류 프롬프트 테스트
- JSON 형식 출력 정확도 → 5번 중 4번 이상 성공이면 합격
- Phi-4 mini vs Qwen 3.5 4B 비교 테스트

### Phase 3: 보안 호환성
- 백그라운드 모델 로드 상태에서 V3/BitDefender 반응 확인
- Tauri 빌드 후 바이너리가 AV에 잡히는지 사전 테스트

---

## 6. 판정

```
현재 등급: B
├── 구조적 접근성: ✅ 완벽 (외부 API 의존 없음, 100% 로컬 데이터)
├── 기술적 실현성: ✅ 높음 (2026년 4B 모델 성능 입증됨)
├── 시장 차별화:   ✅ 명확 (보안 + 로컬 = 클라우드 AI 불가 영역)
├── 수익화 가능성: 🟡 검증 필요 (개인 라이선스 vs 기업 구독)
└── 런칭 허들:     🔴 보안 프로그램 호환성 + 모델 배포 방식 해결 필요

A급 승격 조건:
1. PoC Phase 1~3 통과
2. 구체적 유스케이스 1개 확정 (님의 "파일 정리" 프로젝트와 연계 가능)
3. 보안 프로그램 호환 문제 해결 방안 실증
```

---

*이 파일은 market_assessment/B/secure_local_ai_kr/ 에 보관*
